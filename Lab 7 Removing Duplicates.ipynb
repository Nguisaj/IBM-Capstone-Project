{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf62388-f72b-4ee5-a6db-1661dd4689e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Removing Duplicates\n",
    "\n",
    "Objectives:\n",
    "Identify duplicate rows in the dataset.\n",
    "Use suitable techniques to remove duplicate rows and verify the removal.\n",
    "Summarize how to handle missing values appropriately.\n",
    "Use ConvertedCompYearly to normalize compensation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "650f8977-bfdc-4eb7-9257-1c296591555c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\nguif\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\nguif\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nguif\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nguif\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nguif\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nguif\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d91d4e8-6e6a-4ef1-b861-0d3699411324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the URL of the dataset\n",
    "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to ensure it loaded correctly\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2393c86-2c52-44be-a1dc-b7579488a2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 4: Removing Duplicate Rows\n",
    "Task 2: Remove Duplicates\n",
    "\n",
    "Remove duplicate rows from the dataset using the drop_duplicates() function.\n",
    "Verify the removal by counting the number of duplicate rows after removal ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2393014-c560-492d-8630-e90133b7df87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows before removal: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check the number of duplicate rows BEFORE removal\n",
    "num_duplicates_before = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows before removal: {num_duplicates_before}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f79af3ce-790a-4bef-bae7-793f5fca2123",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Remove duplicate rows\n",
    "df_cleaned = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "760c98b8-15d4-4179-92d2-3fbaab860df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows after removal: 0\n"
     ]
    }
   ],
   "source": [
    "# : Check the number of duplicate rows AFTER removal\n",
    "num_duplicates_after = df_cleaned.duplicated().sum()\n",
    "print(f\"Number of duplicate rows after removal: {num_duplicates_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdd4f9f8-0567-4c13-8073-b0ac90573f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of rows: 65437\n",
      "Number of rows after duplicate removal: 65437\n"
     ]
    }
   ],
   "source": [
    "#  Check the shape of the DataFrame before and after to confirm row count change\n",
    "print(f\"Original number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of rows after duplicate removal: {df_cleaned.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b38d3dd-e625-462a-a17a-28a9061eedf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 5: Handling Missing Values\n",
    "Task 3: Identify and Handle Missing Values\n",
    "\n",
    "Identify missing values for all columns in the dataset.\n",
    "Choose a column with significant missing values (e.g., EdLevel) and impute with the most frequent value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8871315-05fd-4214-a795-50e17ccca89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "\n",
      "ResponseId                 0\n",
      "MainBranch                 0\n",
      "Age                        0\n",
      "Employment                 0\n",
      "RemoteWork             10631\n",
      "                       ...  \n",
      "JobSatPoints_11        35992\n",
      "SurveyLength            9255\n",
      "SurveyEase              9199\n",
      "ConvertedCompYearly    42002\n",
      "JobSat                 36311\n",
      "Length: 114, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#  Identify missing values for all columns\n",
    "missing_values = df_cleaned.isnull().sum()\n",
    "print(\"Missing values per column:\\n\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29ab474c-ad83-4b83-8af4-ac531d124363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in 'EdLevel' column: 4653\n"
     ]
    }
   ],
   "source": [
    "# Choose a column with significant missing values (example: 'EdLevel')\n",
    "# Let's check how many missing values it has:\n",
    "print(f\"\\nMissing values in 'EdLevel' column: {df_cleaned['EdLevel'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60e278f3-9406-42fe-a1aa-2e6cbdbb94df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most frequent value in 'EdLevel': Bachelor’s degree (B.A., B.S., B.Eng., etc.)\n"
     ]
    }
   ],
   "source": [
    "#  Impute missing values in 'EdLevel' with the most frequent value (mode)\n",
    "most_frequent_value = df_cleaned['EdLevel'].mode()[0]\n",
    "print(f\"\\nMost frequent value in 'EdLevel': {most_frequent_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23a594a1-9606-45f1-a9b8-207e47110f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the imputation\n",
    "df_cleaned['EdLevel'] = df_cleaned['EdLevel'].fillna(most_frequent_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "863787aa-f3cd-41fd-85fc-d9c4a0cf81cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in 'EdLevel' after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# Verify that there are no missing values left in 'EdLevel'\n",
    "print(f\"\\nMissing values in 'EdLevel' after imputation: {df_cleaned['EdLevel'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8117a2c9-1a5d-4a6f-8507-84efc3b438b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 6: Normalizing Compensation Data\n",
    "Task 4: Normalize Compensation Data Using ConvertedCompYearly\n",
    "\n",
    "Use the ConvertedCompYearly column for compensation analysis as the normalized annual compensation is already provided.\n",
    "Check for missing values in ConvertedCompYearly and handle them if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0dcb746-967e-40d1-b0e5-eb931dcdde77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in 'ConvertedCompYearly': 42002\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in ConvertedCompYearly\n",
    "missing_converted_comp = df_cleaned['ConvertedCompYearly'].isnull().sum()\n",
    "print(f\"Missing values in 'ConvertedCompYearly': {missing_converted_comp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf75a89a-3ffc-4846-9ec6-5b2e9c37214b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of 'ConvertedCompYearly': 65000.0\n",
      "Missing values in 'ConvertedCompYearly' after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# Calculate the median of ConvertedCompYearly\n",
    "median_converted_comp = df_cleaned['ConvertedCompYearly'].median()\n",
    "print(f\"Median of 'ConvertedCompYearly': {median_converted_comp}\")\n",
    "\n",
    "# Fill missing values with the median (assign the result back)\n",
    "df_cleaned['ConvertedCompYearly'] = df_cleaned['ConvertedCompYearly'].fillna(median_converted_comp)\n",
    "\n",
    "# Verify that there are no missing values now\n",
    "missing_converted_comp_after = df_cleaned['ConvertedCompYearly'].isnull().sum()\n",
    "print(f\"Missing values in 'ConvertedCompYearly' after imputation: {missing_converted_comp_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3492aa52-cf71-4fc7-9ceb-88ea54557f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 7: Summary and Next Steps\n",
    "In this lab, you focused on identifying and removing duplicate rows.\n",
    "\n",
    "You handled missing values by imputing the most frequent value in a chosen column.\n",
    "\n",
    "You used ConvertedCompYearly for compensation normalization and handled missing values.\n",
    "\n",
    "For further analysis, consider exploring other columns or visualizing the cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "795c2334-95a4-4398-82f7-d00c4ccf6bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total missing values remaining in dataset after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# Separate categorical and numerical columns\n",
    "categorical_cols = df_cleaned.select_dtypes(include=['object']).columns\n",
    "numerical_cols = df_cleaned.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Impute categorical columns with the mode\n",
    "for col in categorical_cols:\n",
    "    if df_cleaned[col].isnull().sum() > 0:\n",
    "        mode_value = df_cleaned[col].mode()[0]\n",
    "        df_cleaned[col] = df_cleaned[col].fillna(mode_value)\n",
    "        print(f\"Filled missing values in categorical column '{col}' with mode: {mode_value}\")\n",
    "\n",
    "# Impute numerical columns with the median\n",
    "for col in numerical_cols:\n",
    "    if df_cleaned[col].isnull().sum() > 0:\n",
    "        median_value = df_cleaned[col].median()\n",
    "        df_cleaned[col] = df_cleaned[col].fillna(mode_value)\n",
    "        print(f\"Filled missing values in numerical column '{col}' with median: {median_value}\")\n",
    "\n",
    "# Verify there are no more missing values\n",
    "total_missing_after = df_cleaned.isnull().sum().sum()\n",
    "print(f\"\\nTotal missing values remaining in dataset after imputation: {total_missing_after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e29ded8a-de08-431f-a453-c51cc3910d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved to: C:\\Users\\nguif\\Desktop\\N Power\\Capstone Project\\survey_data_with_duplicate.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the fully cleaned dataset to a CSV file\n",
    "# Define the full save path\n",
    "output_file = r\"C:\\Users\\nguif\\Desktop\\N Power\\Capstone Project\\survey_data_with_duplicate.csv\"\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "df_cleaned.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Cleaned dataset saved to: {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0225c0-80cc-4baa-a65b-789a0802bb56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
